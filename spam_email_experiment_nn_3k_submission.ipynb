{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case study 2: spam email detection from ACIC (neural network)\n",
    "This notebook includes experiments from Case Study 2 from the paper Multi-Source Causal Inference Using Control Variates. Specifically, this notebook contains experiments using the neural network model to estimate the ATE and odds ratios.\n",
    "\n",
    "This experiment uses $n_2 = 3,000$ samples for the dataset without selection bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "import data_sampler\n",
    "import bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = pd.read_csv('spam_binMod11.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = df_orig[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>A</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.00000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3000.00000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.294667</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.319917</td>\n",
       "      <td>0.098823</td>\n",
       "      <td>0.118190</td>\n",
       "      <td>0.10566</td>\n",
       "      <td>0.083893</td>\n",
       "      <td>0.246810</td>\n",
       "      <td>0.062010</td>\n",
       "      <td>0.529727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.15698</td>\n",
       "      <td>0.186447</td>\n",
       "      <td>1.699940</td>\n",
       "      <td>0.101100</td>\n",
       "      <td>0.824350</td>\n",
       "      <td>0.116147</td>\n",
       "      <td>0.107973</td>\n",
       "      <td>0.088857</td>\n",
       "      <td>0.528137</td>\n",
       "      <td>0.972863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.455969</td>\n",
       "      <td>0.417652</td>\n",
       "      <td>0.723370</td>\n",
       "      <td>0.286872</td>\n",
       "      <td>0.426914</td>\n",
       "      <td>0.37970</td>\n",
       "      <td>0.264619</td>\n",
       "      <td>0.591946</td>\n",
       "      <td>0.206386</td>\n",
       "      <td>0.828893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.48656</td>\n",
       "      <td>0.506001</td>\n",
       "      <td>1.778479</td>\n",
       "      <td>0.720557</td>\n",
       "      <td>1.189208</td>\n",
       "      <td>1.044481</td>\n",
       "      <td>0.345529</td>\n",
       "      <td>0.349962</td>\n",
       "      <td>1.744793</td>\n",
       "      <td>0.762200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.479799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.380000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.832909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.632500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.290000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.332102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>6.06000</td>\n",
       "      <td>3.330000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>2.610000</td>\n",
       "      <td>6.450000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.12000</td>\n",
       "      <td>9.090000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>10.710000</td>\n",
       "      <td>17.100000</td>\n",
       "      <td>3.620000</td>\n",
       "      <td>9.090000</td>\n",
       "      <td>20.830000</td>\n",
       "      <td>7.005336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Y            A           V1           V2           V3  \\\n",
       "count  3000.000000  3000.000000  3000.000000  3000.000000  3000.000000   \n",
       "mean      0.294667     0.225000     0.319917     0.098823     0.118190   \n",
       "std       0.455969     0.417652     0.723370     0.286872     0.426914   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     0.000000     0.380000     0.000000     0.000000   \n",
       "max       1.000000     1.000000    10.000000     5.880000     7.270000   \n",
       "\n",
       "               V4           V5           V6           V7           V8  ...  \\\n",
       "count  3000.00000  3000.000000  3000.000000  3000.000000  3000.000000  ...   \n",
       "mean      0.10566     0.083893     0.246810     0.062010     0.529727  ...   \n",
       "std       0.37970     0.264619     0.591946     0.206386     0.828893  ...   \n",
       "min       0.00000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.00000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       0.00000     0.000000     0.000000     0.000000     0.090000  ...   \n",
       "75%       0.00000     0.000000     0.200000     0.000000     0.770000  ...   \n",
       "max       6.06000     3.330000    11.110000     2.610000     6.450000  ...   \n",
       "\n",
       "              V13          V14          V15          V16          V17  \\\n",
       "count  3000.00000  3000.000000  3000.000000  3000.000000  3000.000000   \n",
       "mean      0.15698     0.186447     1.699940     0.101100     0.824350   \n",
       "std       0.48656     0.506001     1.778479     0.720557     1.189208   \n",
       "min       0.00000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.00000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.00000     0.000000     1.380000     0.000000     0.270000   \n",
       "75%       0.00000     0.000000     2.632500     0.000000     1.290000   \n",
       "max       5.12000     9.090000    14.280000    18.180000    10.710000   \n",
       "\n",
       "               V18          V19          V20          V21          V22  \n",
       "count  3000.000000  3000.000000  3000.000000  3000.000000  3000.000000  \n",
       "mean      0.116147     0.107973     0.088857     0.528137     0.972863  \n",
       "std       1.044481     0.345529     0.349962     1.744793     0.762200  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.479799  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.832909  \n",
       "75%       0.000000     0.000000     0.000000     0.000000     1.332102  \n",
       "max      17.100000     3.620000     9.090000    20.830000     7.005336  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orig.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_COLUMN = 'Y'\n",
    "Z_COLUMN = 'A'\n",
    "X_COLUMNS = ['V%d' % i for i in range(1,23)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load selection biased data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_large = pd.read_csv('spam_binMod1_large1.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sampler_selection_bias = data_sampler.DataSampler(Z_COLUMN, X_COLUMNS, Y_COLUMN)\n",
    "df_selection_bias = data_sampler_selection_bias.selection_bias_filter(df_large)\n",
    "df_selection_bias = df_selection_bias.sample(10*len(df_orig), replace=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>A</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.803400</td>\n",
       "      <td>0.184533</td>\n",
       "      <td>0.182096</td>\n",
       "      <td>0.051569</td>\n",
       "      <td>0.034601</td>\n",
       "      <td>0.056220</td>\n",
       "      <td>0.048137</td>\n",
       "      <td>0.193815</td>\n",
       "      <td>0.029849</td>\n",
       "      <td>0.602707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076511</td>\n",
       "      <td>0.114768</td>\n",
       "      <td>1.191797</td>\n",
       "      <td>0.029085</td>\n",
       "      <td>0.449583</td>\n",
       "      <td>0.041853</td>\n",
       "      <td>0.034491</td>\n",
       "      <td>0.032461</td>\n",
       "      <td>1.328376</td>\n",
       "      <td>0.740786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.397434</td>\n",
       "      <td>0.387925</td>\n",
       "      <td>0.513661</td>\n",
       "      <td>0.181610</td>\n",
       "      <td>0.214859</td>\n",
       "      <td>0.280935</td>\n",
       "      <td>0.193812</td>\n",
       "      <td>0.615100</td>\n",
       "      <td>0.145768</td>\n",
       "      <td>1.000305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.287824</td>\n",
       "      <td>0.421061</td>\n",
       "      <td>1.610843</td>\n",
       "      <td>0.308781</td>\n",
       "      <td>0.901698</td>\n",
       "      <td>0.584171</td>\n",
       "      <td>0.200275</td>\n",
       "      <td>0.237237</td>\n",
       "      <td>2.479185</td>\n",
       "      <td>0.556426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.393393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.686626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.920000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.830000</td>\n",
       "      <td>1.000632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.570000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>5.260000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>2.610000</td>\n",
       "      <td>9.670000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.140000</td>\n",
       "      <td>9.090000</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>17.100000</td>\n",
       "      <td>5.450000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>20.830000</td>\n",
       "      <td>7.005336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Y             A            V1            V2            V3  \\\n",
       "count  30000.000000  30000.000000  30000.000000  30000.000000  30000.000000   \n",
       "mean       0.803400      0.184533      0.182096      0.051569      0.034601   \n",
       "std        0.397434      0.387925      0.513661      0.181610      0.214859   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      0.000000      0.090000      0.000000      0.000000   \n",
       "max        1.000000      1.000000     10.000000      3.570000      7.270000   \n",
       "\n",
       "                 V4            V5            V6            V7            V8  \\\n",
       "count  30000.000000  30000.000000  30000.000000  30000.000000  30000.000000   \n",
       "mean       0.056220      0.048137      0.193815      0.029849      0.602707   \n",
       "std        0.280935      0.193812      0.615100      0.145768      1.000305   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.860000   \n",
       "max       11.110000      5.260000     18.180000      2.610000      9.670000   \n",
       "\n",
       "       ...           V13           V14           V15           V16  \\\n",
       "count  ...  30000.000000  30000.000000  30000.000000  30000.000000   \n",
       "mean   ...      0.076511      0.114768      1.191797      0.029085   \n",
       "std    ...      0.287824      0.421061      1.610843      0.308781   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.510000      0.000000   \n",
       "75%    ...      0.000000      0.000000      1.920000      0.000000   \n",
       "max    ...      7.140000      9.090000     18.750000     18.180000   \n",
       "\n",
       "                V17           V18           V19           V20           V21  \\\n",
       "count  30000.000000  30000.000000  30000.000000  30000.000000  30000.000000   \n",
       "mean       0.449583      0.041853      0.034491      0.032461      1.328376   \n",
       "std        0.901698      0.584171      0.200275      0.237237      2.479185   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.630000      0.000000      0.000000      0.000000      1.830000   \n",
       "max       11.110000     17.100000      5.450000     12.500000     20.830000   \n",
       "\n",
       "                V22  \n",
       "count  30000.000000  \n",
       "mean       0.740786  \n",
       "std        0.556426  \n",
       "min        0.000000  \n",
       "25%        0.393393  \n",
       "50%        0.686626  \n",
       "75%        1.000632  \n",
       "max        7.005336  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_selection_bias.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Varying coefficient model with neural network function approximation\n",
    "\n",
    "In this section, we assume the data is generated from \n",
    "\n",
    "$$P(Y=1 | Z = z, X = x) = \\frac{e^{\\beta_0^x + \\beta_1^x z}}{ 1 + e^{\\beta_0^x + \\beta_1^xz}}$$\n",
    "\n",
    "where $\\beta_0^x, \\beta_1^x$ are functions of $x$:\n",
    "$$\\beta_0^x = f_0(x; \\theta_0), \\quad \\beta_1^x = f_1(x; \\theta_1)$$\n",
    "\n",
    "If we were to assume $\\beta_0^x, \\beta_1^x$ were linear in $x$, this would be equivalent to the above logistic regression model with explicit interaction terms.\n",
    "\n",
    "To model more complicated interactions, we allow $f_0(x; \\theta_0), f_1(x; \\theta_1)$ to be nonlinear in $x$, and set these to be generated from a two layer neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose hyperparameters using 5-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sampler_nn = data_sampler.DataSamplerNN(Z_COLUMN, X_COLUMNS, Y_COLUMN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with num_hidden_layers=4, hidden_dim=4\n",
      "Accuracy for outcome model: 0.845000\n",
      "AUC for outcome model: 0.902785\n",
      "Accuracy for outcome model: 0.858333\n",
      "AUC for outcome model: 0.871247\n",
      "Accuracy for outcome model: 0.848333\n",
      "AUC for outcome model: 0.897701\n",
      "Accuracy for outcome model: 0.858333\n",
      "AUC for outcome model: 0.895902\n",
      "Accuracy for outcome model: 0.861667\n",
      "AUC for outcome model: 0.936662\n",
      "average CV accuracy: 0.8543333333333333\n",
      "Optimizing with num_hidden_layers=4, hidden_dim=8\n",
      "Accuracy for outcome model: 0.830000\n",
      "AUC for outcome model: 0.888189\n",
      "Accuracy for outcome model: 0.855000\n",
      "AUC for outcome model: 0.930459\n",
      "Accuracy for outcome model: 0.838333\n",
      "AUC for outcome model: 0.866574\n",
      "Accuracy for outcome model: 0.848333\n",
      "AUC for outcome model: 0.848111\n",
      "Accuracy for outcome model: 0.866667\n",
      "AUC for outcome model: 0.924754\n",
      "average CV accuracy: 0.8476666666666667\n",
      "Optimizing with num_hidden_layers=4, hidden_dim=16\n",
      "Accuracy for outcome model: 0.836667\n",
      "AUC for outcome model: 0.829224\n",
      "Accuracy for outcome model: 0.853333\n",
      "AUC for outcome model: 0.926109\n",
      "Accuracy for outcome model: 0.696667\n",
      "AUC for outcome model: 0.553032\n",
      "Accuracy for outcome model: 0.860000\n",
      "AUC for outcome model: 0.897997\n",
      "Accuracy for outcome model: 0.860000\n",
      "AUC for outcome model: 0.939371\n",
      "average CV accuracy: 0.8213333333333332\n",
      "Optimizing with num_hidden_layers=4, hidden_dim=32\n",
      "Accuracy for outcome model: 0.835000\n",
      "AUC for outcome model: 0.882071\n",
      "Accuracy for outcome model: 0.850000\n",
      "AUC for outcome model: 0.923308\n",
      "Accuracy for outcome model: 0.861667\n",
      "AUC for outcome model: 0.890912\n",
      "Accuracy for outcome model: 0.861667\n",
      "AUC for outcome model: 0.890715\n",
      "Accuracy for outcome model: 0.846667\n",
      "AUC for outcome model: 0.916505\n",
      "average CV accuracy: 0.8510000000000002\n",
      "Optimizing with num_hidden_layers=8, hidden_dim=4\n",
      "Accuracy for outcome model: 0.845000\n",
      "AUC for outcome model: 0.909221\n",
      "Accuracy for outcome model: 0.858333\n",
      "AUC for outcome model: 0.932165\n",
      "Accuracy for outcome model: 0.853333\n",
      "AUC for outcome model: 0.907704\n",
      "Accuracy for outcome model: 0.843333\n",
      "AUC for outcome model: 0.897473\n",
      "Accuracy for outcome model: 0.871667\n",
      "AUC for outcome model: 0.946402\n",
      "average CV accuracy: 0.8543333333333333\n",
      "Optimizing with num_hidden_layers=8, hidden_dim=8\n",
      "Accuracy for outcome model: 0.841667\n",
      "AUC for outcome model: 0.896137\n",
      "Accuracy for outcome model: 0.865000\n",
      "AUC for outcome model: 0.933429\n",
      "Accuracy for outcome model: 0.853333\n",
      "AUC for outcome model: 0.907178\n",
      "Accuracy for outcome model: 0.861667\n",
      "AUC for outcome model: 0.909088\n",
      "Accuracy for outcome model: 0.883333\n",
      "AUC for outcome model: 0.949166\n",
      "average CV accuracy: 0.861\n",
      "Optimizing with num_hidden_layers=8, hidden_dim=16\n",
      "Accuracy for outcome model: 0.846667\n",
      "AUC for outcome model: 0.903197\n",
      "Accuracy for outcome model: 0.873333\n",
      "AUC for outcome model: 0.928193\n",
      "Accuracy for outcome model: 0.853333\n",
      "AUC for outcome model: 0.914894\n",
      "Accuracy for outcome model: 0.848333\n",
      "AUC for outcome model: 0.894276\n",
      "Accuracy for outcome model: 0.876667\n",
      "AUC for outcome model: 0.947373\n",
      "average CV accuracy: 0.8596666666666668\n",
      "Optimizing with num_hidden_layers=8, hidden_dim=32\n",
      "Accuracy for outcome model: 0.845000\n",
      "AUC for outcome model: 0.903130\n",
      "Accuracy for outcome model: 0.863333\n",
      "AUC for outcome model: 0.940150\n",
      "Accuracy for outcome model: 0.851667\n",
      "AUC for outcome model: 0.912699\n",
      "Accuracy for outcome model: 0.856667\n",
      "AUC for outcome model: 0.901414\n",
      "Accuracy for outcome model: 0.863333\n",
      "AUC for outcome model: 0.936895\n",
      "average CV accuracy: 0.8560000000000001\n"
     ]
    }
   ],
   "source": [
    "# Optimize for best hyperparams using 5-fold cross validation. \n",
    "num_hidden_layers_list = [4, 8]\n",
    "hidden_dim_list = [4, 8, 16, 32]\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 0)\n",
    "    \n",
    "best_accuracy = 0.0\n",
    "best_hidden_dim = None\n",
    "best_num_hidden_layers = None\n",
    "for num_hidden_layers in num_hidden_layers_list:\n",
    "    for hidden_dim in hidden_dim_list:\n",
    "        print(\"Optimizing with num_hidden_layers=%d, hidden_dim=%d\" % (num_hidden_layers, hidden_dim))\n",
    "        CV_accuracies = []\n",
    "        for train_index, test_index in kf.split(df_orig):\n",
    "            df_train = df_orig.iloc[train_index]\n",
    "            df_test =  df_orig.iloc[test_index]\n",
    "            _ = data_sampler_nn.fit_outcome(df_train, \n",
    "                                            num_hidden_layers=num_hidden_layers, \n",
    "                                            hidden_dim=hidden_dim, \n",
    "                                            batch_size=3000, \n",
    "                                            epochs=1000, \n",
    "                                            step_size=0.001, \n",
    "                                            verbose=0, \n",
    "                                            print_metrics=False)\n",
    "            accuracy = data_sampler_nn.print_metrics(df_test)\n",
    "            CV_accuracies.append(accuracy)\n",
    "        avg_CV_accuracy = np.mean(CV_accuracies)\n",
    "        print(\"average CV accuracy:\", avg_CV_accuracy)\n",
    "        if avg_CV_accuracy > best_accuracy: \n",
    "            best_num_hidden_layers = num_hidden_layers\n",
    "            best_hidden_dim = hidden_dim\n",
    "            best_accuracy = avg_CV_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best cross validation accuracy: 0.861\n",
      "best hidden_dim: 8\n",
      "best num_hidden_layers: 8\n"
     ]
    }
   ],
   "source": [
    "print(\"best cross validation accuracy:\", best_accuracy)\n",
    "print(\"best hidden_dim:\", best_hidden_dim)\n",
    "print(\"best num_hidden_layers:\", best_num_hidden_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute ATE estimates with and without control variate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ATE_estimator_fn_interaction(df_input):\n",
    "    data_sampler_nn = data_sampler.DataSamplerNN(Z_COLUMN, X_COLUMNS, Y_COLUMN)\n",
    "    data_sampler_nn.fit_outcome(df_input, \n",
    "                                num_hidden_layers=8, \n",
    "                                hidden_dim=8, \n",
    "                                batch_size=3000, \n",
    "                                epochs=1000, \n",
    "                                step_size=0.001, \n",
    "                                verbose=0, \n",
    "                                print_metrics=False)\n",
    "    return data_sampler_nn.get_ATE_estimate(df_input)\n",
    "\n",
    "def CV_estimator_fn_interaction(df_input_obs, df_input_bias):\n",
    "    data_sampler_nn = data_sampler.DataSamplerNN(Z_COLUMN, X_COLUMNS, Y_COLUMN)\n",
    "    OR_xs = df_input_obs[X_COLUMNS] # Average over all xs in the observational dataset.\n",
    "    # Estimate OR from observational dataset\n",
    "    data_sampler_nn.fit_outcome(df_input_obs, \n",
    "                                num_hidden_layers=8, \n",
    "                                hidden_dim=8, \n",
    "                                batch_size=3000, \n",
    "                                epochs=1000, \n",
    "                                step_size=0.001, \n",
    "                                verbose=0, \n",
    "                                print_metrics=False)\n",
    "    OR_obs = np.mean(data_sampler_nn.get_conditional_OR_estimates(OR_xs))\n",
    "    # Estimate OR from selection bias dataset\n",
    "    data_sampler_nn.fit_outcome(df_input_bias, \n",
    "                                num_hidden_layers=8, \n",
    "                                hidden_dim=8, \n",
    "                                batch_size=3000, \n",
    "                                epochs=1000, \n",
    "                                step_size=0.001, \n",
    "                                verbose=0, \n",
    "                                print_metrics=False)\n",
    "    OR_bias = np.mean(data_sampler_nn.get_conditional_OR_estimates(OR_xs))\n",
    "    return OR_obs - OR_bias\n",
    "\n",
    "CV_samples, ATE_hat_samples, _ = bootstrap.run_bootstrap_df(df_obs=df_orig, \n",
    "              df_bias=df_selection_bias, \n",
    "              n_replicates=300, \n",
    "              ATE_estimator_fn=ATE_estimator_fn_interaction,\n",
    "              CV_estimator_fn=CV_estimator_fn_interaction,\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cov_ATE_CV: 0.010320750224568166\n",
      "var_CV: 97.07312314304782\n",
      "optimal CV coefficient: 0.00010631933835444252\n"
     ]
    }
   ],
   "source": [
    "sample_cov = np.cov(np.array([ATE_hat_samples, CV_samples]), ddof=1)\n",
    "\n",
    "# Get optimal control variates coefficient\n",
    "cov_ATE_CV = sample_cov[0][1]\n",
    "var_CV = sample_cov[1][1]\n",
    "optimal_CV_coeff = cov_ATE_CV / var_CV\n",
    "print(\"cov_ATE_CV:\", cov_ATE_CV)\n",
    "print(\"var_CV:\", var_CV)\n",
    "print(\"optimal CV coefficient:\", optimal_CV_coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting replicate 299\r"
     ]
    }
   ],
   "source": [
    "# Get variance/bias of ATE estimators with and without CV.\n",
    "CV_samples, ATE_hat_samples, ATE_hat_CV_samples = bootstrap.run_bootstrap_df(\n",
    "    df_obs=df_orig, \n",
    "    df_bias=df_selection_bias, \n",
    "    n_replicates=300, # Try increasing this\n",
    "    ATE_estimator_fn=ATE_estimator_fn_interaction,\n",
    "    CV_estimator_fn=CV_estimator_fn_interaction,\n",
    "    optimal_CV_coeff=optimal_CV_coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Variance of ATE estimator: 0.0010743029\n",
      ">>> Bias of ATE estimator: -0.010947475157441197\n",
      ">>> Variance of ATE estimator with CV: 0.0010674468592391608\n",
      ">>> Bias of ATE estimator with CV: -0.011286787382429164\n"
     ]
    }
   ],
   "source": [
    "ATE_true = 0.106286795757474\n",
    "\n",
    "ATE_var = np.var(np.array(ATE_hat_samples), ddof=1)\n",
    "print(\">>> Variance of ATE estimator:\", ATE_var)\n",
    "\n",
    "ATE_bias = np.mean(np.array(ATE_hat_samples)) - ATE_true\n",
    "print(\">>> Bias of ATE estimator:\", ATE_bias)\n",
    "\n",
    "ATE_CV_var = np.var(np.array(ATE_hat_CV_samples), ddof=1)\n",
    "print(\">>> Variance of ATE estimator with CV:\", ATE_CV_var)\n",
    "\n",
    "ATE_CV_bias = np.mean(np.array(ATE_hat_CV_samples)) - ATE_true\n",
    "print(\">>> Bias of ATE estimator with CV:\", ATE_CV_bias)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
